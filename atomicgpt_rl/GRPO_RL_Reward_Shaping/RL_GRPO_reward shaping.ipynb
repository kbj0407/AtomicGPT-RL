{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700,
          "referenced_widgets": [
            "d8d0dca36cfc47f0919924da07c231e8",
            "5f3d96b613e94e9984d4599ca9ca7b17",
            "66c3271554b1455eb56be55c9241e45e",
            "d36b61cf796c429080e93ea838a3759e",
            "94873c3c077e483790b34f95c421f484",
            "ea549fffa8c2469888d1668158bc105c",
            "98b432b98839428f85d91580c21e80e2",
            "fee4f852c9744a07b909e586e3615604",
            "3febcf8a8eca40c28aafc697f3ec8776",
            "b4e1eb8eeb064c88a2142e474fb8327f",
            "da10502506f9448c9de94f1ddd84d3b1",
            "e6cc388e78c14abfaa49d2be6fa1b5d9",
            "769bde36e2ba4434bddd78e7d5911be4",
            "3c522d78b1834068bd4b155d0f87a4d7",
            "a23afba19c2a4d3a90d771fc55f8d490",
            "6221f0be3b8d48e797c873565a216680",
            "1ac03aff5c314b00ac938c80eb7b2f8a",
            "88c63d94a05a42c49d5f8958a27987a6",
            "0ca67b0c4ca64eb788358a51308f6b97",
            "83c3c811923a4642aba156d1215b39d2",
            "e863bf099e064da7b482c21fe7b77de7",
            "697faad6643a43aca98015da4faef186"
          ]
        },
        "id": "DkIvEkIIkEyB",
        "outputId": "514dea04-804e-47a8-b891-ed3f4a6fb530"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "from peft import LoraConfig, get_peft_model\n",
        "import logging\n",
        "import os\n",
        "\n",
        "# GPU 설정 - 명시적으로 9번 GPU만 사용하도록 설정(실제 연구 환경에 맞게 설정)\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"9\"\n",
        "\n",
        "# 설정 즉시 확인\n",
        "print(f\"CUDA_VISIBLE_DEVICES 설정: {os.environ['CUDA_VISIBLE_DEVICES']}\")\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "# GPU 상태 확인\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "print(f\"Visible devices: {os.environ.get('CUDA_VISIBLE_DEVICES', 'Not set')}\")\n",
        "print(f\"Device count: {torch.cuda.device_count()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"Current device: {torch.cuda.current_device()}\")\n",
        "    print(f\"Device name: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "# 사용할 장치 설정: CUDA_VISIBLE_DEVICES로 지정된 GPU의 0번 인덱스 사용\n",
        "# CUDA_VISIBLE_DEVICES=\"9\"로 설정했으므로 0번이 실제 9번 GPU가 됨\n",
        "device = torch.device(\"cuda:0\")  \n",
        "logging.info(f\"Using device: {device}\")\n",
        "\n",
        "# 추가 확인을 위한 코드\n",
        "if torch.cuda.is_available():\n",
        "    # 현재 사용 중인 GPU의 UUID 확인 (고유 식별자)\n",
        "    current_device = torch.cuda.current_device()\n",
        "    device_props = torch.cuda.get_device_properties(current_device)\n",
        "    print(f\"Using GPU: {device_props.name}\")\n",
        "    print(f\"GPU Memory: {device_props.total_memory / 1024**3:.2f} GB\")\n",
        "\n",
        "# bfloat16 지원 여부 확인\n",
        "is_bfloat16 = torch.cuda.is_bf16_supported()\n",
        "logging.info(f\"bfloat16 supported: {is_bfloat16}\")\n",
        "\n",
        "# 모델 설정값\n",
        "max_seq_len = 1024  # 긴 문맥 추론을 위해 증가 가능\n",
        "logging.info(f\"Max Sequence length set to: {max_seq_len}\")\n",
        "\n",
        "lora_rank = 16  # 클수록 성능이 좋지만 속도 저하\n",
        "\n",
        "# 로컬 경로 설정\n",
        "local_model_path = \"/home/qudwo9246/GRPO/AtomicGPT-gemma2-9B\"\n",
        "local_tokenizer_path = \"/home/qudwo9246/GRPO/AtomicGPT-gemma2-9B\"\n",
        "\n",
        "# 4비트 양자화 설정\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        ")\n",
        "\n",
        "# 토크나이저 로드\n",
        "try:\n",
        "    tokenizer = AutoTokenizer.from_pretrained(local_tokenizer_path)\n",
        "    logging.info(\"토크나이저 로드 완료\")\n",
        "except Exception as e:\n",
        "    logging.error(\"토크나이저 로드 중 오류 발생:\", exc_info=True)\n",
        "    raise e\n",
        "\n",
        "# 모델 로드\n",
        "try:\n",
        "    # device_map을 명시적으로 \"cuda:0\"으로 설정\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        local_model_path,\n",
        "        quantization_config=bnb_config,  # 4bit 양자화 적용\n",
        "        device_map=\"cuda:0\",  # 명시적으로 cuda:0 지정\n",
        "        attn_implementation=\"eager\"\n",
        "    )\n",
        "    model.config.max_position_embeddings = max_seq_len\n",
        "    logging.info(\"모델 로드 완료\")\n",
        "    # 모델이 어떤 장치에 로드되었는지 확인\n",
        "    print(f\"Model device: {next(model.parameters()).device}\")\n",
        "except Exception as e:\n",
        "    logging.error(\"모델 로드 중 오류 발생:\", exc_info=True)\n",
        "    raise e\n",
        "\n",
        "# LoRA 설정 적용\n",
        "peft_config = LoraConfig(\n",
        "    r=lora_rank,\n",
        "    lora_alpha=2*lora_rank,\n",
        "    target_modules=[\n",
        "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "        \"gate_proj\", \"up_proj\", \"down_proj\",\n",
        "    ],\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "\n",
        "# PEFT 적용\n",
        "try:\n",
        "    model = get_peft_model(model, peft_config)\n",
        "    logging.info(\"PEFT 적용 완료\")\n",
        "except Exception as e:\n",
        "    logging.error(\"PEFT 설정 중 오류 발생:\", exc_info=True)\n",
        "    raise e\n",
        "\n",
        "# 모델 정보 출력\n",
        "first_layer = model.base_model.model.model.layers[0].self_attn.q_proj\n",
        "print(f\"First layer weight dtype: {first_layer.weight.dtype}\")\n",
        "print(f\"Model is quantized: {model.is_quantized}\")\n",
        "\n",
        "print(\"모델 및 LoRA 설정 완료!\")\n",
        "print(\"Max position embeddings:\", model.config.max_position_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "cXk993X6C2ZZ"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from datasets import load_dataset, Dataset\n",
        "\n",
        "# Load and prep dataset\n",
        "SYSTEM_PROMPT = \"\"\"\n",
        "Respond in the following format:\n",
        "<reasoning>\n",
        "...\n",
        "</reasoning>\n",
        "<answer>\n",
        "...\n",
        "</answer>\n",
        "\"\"\"\n",
        "\n",
        "XML_COT_FORMAT = \"\"\"\\\n",
        "<reasoning>\n",
        "{reasoning}\n",
        "</reasoning>\n",
        "<answer>\n",
        "{answer}\n",
        "</answer>\n",
        "\"\"\"\n",
        "\n",
        "def extract_xml_answer(text: str) -> str:\n",
        "    \"\"\"XML 태그에서 답변을 추출하고, 실패하면 다른 방법으로 시도합니다.\"\"\"\n",
        "    try:\n",
        "        # 기본 XML 추출 시도\n",
        "        if \"<answer>\" in text and \"</answer>\" in text:\n",
        "            answer = text.split(\"<answer>\")[-1]\n",
        "            answer = answer.split(\"</answer>\")[0]\n",
        "            return answer.strip()\n",
        "        \n",
        "        # \"Answer:\" 키워드로 시도\n",
        "        elif \"Answer:\" in text:\n",
        "            answer = text.split(\"Answer:\")[-1].strip()\n",
        "            # 다음 줄바꿈이나 문장 끝까지 추출\n",
        "            if \"\\n\" in answer:\n",
        "                answer = answer.split(\"\\n\")[0]\n",
        "            return answer.strip()\n",
        "        \n",
        "        # 마지막 문장 시도 (최후의 수단)\n",
        "        sentences = re.split(r'[.!?]', text)\n",
        "        # 비어있지 않은 마지막 문장들 중 숫자가 포함된 것 찾기\n",
        "        for sentence in reversed(sentences):\n",
        "            if sentence.strip() and re.search(r'\\d+', sentence):\n",
        "                return sentence.strip()\n",
        "        \n",
        "        # 아무것도 찾지 못했으면 빈 문자열 반환\n",
        "        return \"\"\n",
        "    except Exception:\n",
        "        return \"\"\n",
        "\n",
        "def extract_hash_answer(text: str) -> str | None:\n",
        "    if \"####\" not in text:\n",
        "        return None\n",
        "    return text.split(\"####\")[1].strip()\n",
        "\n",
        "# uncomment middle messages for 1-shot prompting\n",
        "def get_gsm8k_questions(split = \"train\") -> Dataset:\n",
        "    data = load_dataset('openai/gsm8k', 'main')[split] # type: ignore\n",
        "    data = data.map(lambda x: { # type: ignore\n",
        "        'prompt': [\n",
        "            {'role': 'system', 'content': SYSTEM_PROMPT},\n",
        "            {'role': 'user', 'content': x['question']}\n",
        "        ],\n",
        "        'answer': extract_hash_answer(x['answer'])\n",
        "    }) # type: ignore\n",
        "    return data # type: ignore\n",
        "\n",
        "dataset = get_gsm8k_questions()\n",
        "\n",
        "# 숫자 추출 및 비교를 위한 유틸리티 함수\n",
        "def extract_final_number(text: str) -> float | None:\n",
        "    \"\"\"텍스트에서 가장 관련성 높은 숫자를 추출합니다.\"\"\"\n",
        "    if not text:\n",
        "        return None\n",
        "    \n",
        "    # 결론 문장에서 숫자 찾기 시도\n",
        "    conclusion_patterns = [\n",
        "        r\"Therefore,.*?(\\d+)\",\n",
        "        r\"Thus,.*?(\\d+)\",\n",
        "        r\"In total,.*?(\\d+)\",\n",
        "        r\"The answer is.*?(\\d+)\",\n",
        "        r\"The result is.*?(\\d+)\",\n",
        "        r\"equals.*?(\\d+)\"\n",
        "    ]\n",
        "    \n",
        "    for pattern in conclusion_patterns:\n",
        "        match = re.search(pattern, text, re.IGNORECASE)\n",
        "        if match:\n",
        "            try:\n",
        "                return float(match.group(1))\n",
        "            except ValueError:\n",
        "                pass\n",
        "    \n",
        "    # 모든 숫자 찾기\n",
        "    numbers = re.findall(r'(\\d+(?:\\.\\d+)?)', text)\n",
        "    if numbers:\n",
        "        try:\n",
        "            # 마지막 숫자 반환 (일반적으로 최종 결과)\n",
        "            return float(numbers[-1])\n",
        "        except ValueError:\n",
        "            pass\n",
        "    \n",
        "    return None\n",
        "\n",
        "def compare_numbers(expected_str: str, actual_str: str) -> bool:\n",
        "    \"\"\"두 텍스트에서 숫자를 추출하여 비교합니다.\"\"\"\n",
        "    expected_num = extract_final_number(expected_str)\n",
        "    actual_num = extract_final_number(actual_str)\n",
        "    \n",
        "    if expected_num is not None and actual_num is not None:\n",
        "        # 소수점 이하 6자리까지 비교 (부동소수점 오차 허용)\n",
        "        return abs(expected_num - actual_num) < 1e-6\n",
        "    return False\n",
        "\n",
        "# Reward functions\n",
        "def correctness_reward_func(prompts, completions, answer, **kwargs) -> list[float]:\n",
        "    \"\"\"모델의 출력에서 정답을 추출하여 비교하고 보상을 계산합니다.\"\"\"\n",
        "    responses = [completion[0]['content'] for completion in completions]\n",
        "    q = prompts[0][-1]['content'] if prompts and len(prompts[0]) > 0 else \"N/A\"\n",
        "    \n",
        "    rewards = []\n",
        "    \n",
        "    for idx, (response, expected_answer) in enumerate(zip(responses, answer)):\n",
        "        # 디버깅 정보 출력 (첫 번째 샘플만)\n",
        "        if idx == 0:\n",
        "            print('-'*20)\n",
        "            print(f\"Question:\\n{q}\")\n",
        "            print(f\"Expected Answer:\\n{expected_answer if expected_answer else 'N/A'}\")\n",
        "            print(f\"Full Response:\\n{response if response else 'N/A'}\")\n",
        "        \n",
        "        # 정답이 없으면 0점\n",
        "        if not expected_answer:\n",
        "            rewards.append(0.0)\n",
        "            continue\n",
        "        \n",
        "        # 숫자 정답인 경우 숫자 추출\n",
        "        expected_num = extract_final_number(expected_answer)\n",
        "        \n",
        "        # 1. 답변 추출 알고리즘을 사용하여 답변 추출\n",
        "        extracted_answer = extract_xml_answer(response)\n",
        "        \n",
        "        if idx == 0:\n",
        "            print(f\"Extracted Answer: {extracted_answer}\")\n",
        "        \n",
        "        # 추출된 답변이 없으면 0점\n",
        "        if not extracted_answer:\n",
        "            rewards.append(0.0)\n",
        "            if idx == 0:\n",
        "                print(f\"✗ No answer extracted! Reward: 0.0\")\n",
        "            continue\n",
        "        \n",
        "        # 숫자 정답인 경우\n",
        "        if expected_num is not None:\n",
        "            actual_num = extract_final_number(extracted_answer)\n",
        "            \n",
        "            if idx == 0:\n",
        "                print(f\"Expected Number: {expected_num}, Extracted Number: {actual_num}\")\n",
        "            \n",
        "            # 숫자가 정확히 일치하는 경우\n",
        "            if actual_num is not None and abs(actual_num - expected_num) < 1e-6:\n",
        "                # 추출된 답변이 숫자만 있거나 단위만 포함된 경우 (예: \"110\" 또는 \"110 miles\")\n",
        "                if re.match(r'^\\s*\\$?\\d+(\\.\\d+)?\\s*$', extracted_answer) or re.match(r'^\\s*\\d+(\\.\\d+)?\\s*[a-zA-Z]+\\s*$', extracted_answer):\n",
        "                    rewards.append(2.0)  # 정확한 숫자만 있으면 2.0 보상\n",
        "                    if idx == 0:\n",
        "                        print(f\"✓ CORRECT with exact number! Reward: 2.0\")\n",
        "                else:\n",
        "                    rewards.append(1.5)  # 정확한 숫자가 있지만 추가 텍스트도 있으면 1.5 보상\n",
        "                    if idx == 0:\n",
        "                        print(f\"✓ CORRECT with additional text! Reward: 1.5\")\n",
        "            else:\n",
        "                rewards.append(0.0)  # 숫자가 일치하지 않으면 0 보상\n",
        "                if idx == 0:\n",
        "                    print(f\"✗ INCORRECT number! Reward: 0.0\")\n",
        "        \n",
        "        # 숫자가 아닌 정답인 경우 (텍스트 비교)\n",
        "        else:\n",
        "            # 정답 텍스트 정규화 (대소문자, 공백 등 무시)\n",
        "            normalized_expected = expected_answer.lower().strip()\n",
        "            normalized_extracted = extracted_answer.lower().strip()\n",
        "            \n",
        "            if idx == 0:\n",
        "                print(f\"Text comparison - Expected: '{normalized_expected}', Actual: '{normalized_extracted}'\")\n",
        "            \n",
        "            # 정확히 일치하는 경우\n",
        "            if normalized_expected == normalized_extracted:\n",
        "                rewards.append(2.0)\n",
        "                if idx == 0:\n",
        "                    print(f\"✓ CORRECT with exact match! Reward: 2.0\")\n",
        "            # 부분 일치하는 경우 (핵심 키워드가 포함된 경우)\n",
        "            elif normalized_expected in normalized_extracted or normalized_extracted in normalized_expected:\n",
        "                rewards.append(1.5)\n",
        "                if idx == 0:\n",
        "                    print(f\"✓ CORRECT with partial match! Reward: 1.5\")\n",
        "            else:\n",
        "                rewards.append(0.0)\n",
        "                if idx == 0:\n",
        "                    print(f\"✗ INCORRECT text! Reward: 0.0\")\n",
        "    \n",
        "    return rewards\n",
        "\n",
        "def int_reward_func(completions, **kwargs) -> list[float]:\n",
        "    \"\"\"출력에 숫자가 포함되어 있으면 보상을 줍니다.\"\"\"\n",
        "    responses = [completion[0]['content'] for completion in completions]\n",
        "    \n",
        "    # 전체 응답에서 숫자 찾기\n",
        "    rewards = []\n",
        "    for r in responses:\n",
        "        if re.search(r'\\d+', r):\n",
        "            rewards.append(0.5)\n",
        "        else:\n",
        "            rewards.append(0.0)\n",
        "    \n",
        "    return rewards\n",
        "\n",
        "def strict_format_reward_func(completions, **kwargs) -> list[float]:\n",
        "    \"\"\"응답이 정확한 XML 형식을 따르는지 확인하고 보상을 줍니다.\"\"\"\n",
        "    # 정확한 XML 형식 패턴\n",
        "    pattern = r\"^<reasoning>\\n.*?\\n</reasoning>\\n<answer>\\n.*?\\n</answer>\\n$\"\n",
        "    responses = [completion[0][\"content\"] for completion in completions]\n",
        "    \n",
        "    rewards = []\n",
        "    for r in responses:\n",
        "        if re.search(pattern, r, re.DOTALL):\n",
        "            rewards.append(0.5)\n",
        "        else:\n",
        "            rewards.append(0.0)\n",
        "    \n",
        "    return rewards\n",
        "\n",
        "def soft_format_reward_func(completions, **kwargs) -> list[float]:\n",
        "    \"\"\"응답이 유연한 형식(XML 또는 키워드)을 따르는지 확인하고 보상을 줍니다.\"\"\"\n",
        "    # XML 형식 또는 키워드 형식 패턴\n",
        "    pattern = r\"<reasoning>.*?</reasoning>\\s*<answer>.*?</answer>\"\n",
        "    \n",
        "    responses = [completion[0][\"content\"] for completion in completions]\n",
        "    \n",
        "    rewards = []\n",
        "    for r in responses:\n",
        "        if re.search(pattern, r, re.DOTALL):\n",
        "            rewards.append(0.25)\n",
        "        else:\n",
        "            rewards.append(0.0)\n",
        "    \n",
        "    return rewards\n",
        "\n",
        "def count_xml(text) -> float:\n",
        "    \"\"\"XML 태그 또는 키워드의 존재 여부에 따라 보상을 계산합니다.\"\"\"\n",
        "    if not text:\n",
        "        return 0.0\n",
        "        \n",
        "    count = 0.0\n",
        "    # XML 태그 확인\n",
        "    if \"<reasoning>\" in text:\n",
        "        count += 0.125\n",
        "    if \"</reasoning>\" in text:\n",
        "        count += 0.125\n",
        "    if \"<answer>\" in text:\n",
        "        count += 0.125\n",
        "    if \"</answer>\" in text:\n",
        "        count += 0.125\n",
        "    \n",
        "    # 대체 형식 확인 (XML 태그가 없는 경우에도 일부 보상)\n",
        "    if \"Reasoning:\" in text:\n",
        "        count += 0.0625\n",
        "    if \"Answer:\" in text:\n",
        "        count += 0.0625\n",
        "        \n",
        "    return count\n",
        "\n",
        "def xmlcount_reward_func(completions, **kwargs) -> list[float]:\n",
        "    \"\"\"응답에서 XML 태그 또는 키워드의 존재 여부를 측정하여 보상합니다.\"\"\"\n",
        "    contents = [completion[0][\"content\"] for completion in completions]\n",
        "    return [count_xml(c) for c in contents]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import time\n",
        "import logging\n",
        "from datetime import datetime\n",
        "import google.generativeai as genai\n",
        "\n",
        "# 여기에 API 키 입력\n",
        "GEMINI_API_KEY = \"\"  # 실제 사용 시 이 부분에 API 키를 넣으세요\n",
        "os.environ['GEMINI_API_KEY'] = GEMINI_API_KEY\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "\n",
        "# Gemini API 설정 (간소화)\n",
        "def setup_gemini():\n",
        "    \"\"\"Gemini API 설정\"\"\"\n",
        "    return genai.GenerativeModel('gemini-2.0-flash-thinking-exp')\n",
        "\n",
        "# 로깅 설정\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "    handlers=[\n",
        "        logging.FileHandler(\"gemini_evaluation.log\"),\n",
        "        logging.StreamHandler()\n",
        "    ]\n",
        ")\n",
        "logger = logging.getLogger(\"gemini_evaluator\")\n",
        "\n",
        "# 피드백 캐시 초기화\n",
        "reasoning_score_cache = {}\n",
        "# 평가 결과를 저장할 전역 리스트\n",
        "evaluation_history = []\n",
        "\n",
        "def extract_reasoning(text: str) -> str:\n",
        "    \"\"\"<reasoning> 태그 내용을 추출합니다.\"\"\"\n",
        "    try:\n",
        "        if \"<reasoning>\" in text and \"</reasoning>\" in text:\n",
        "            reasoning = text.split(\"<reasoning>\")[-1]\n",
        "            reasoning = reasoning.split(\"</reasoning>\")[0]\n",
        "            return reasoning.strip()\n",
        "        return \"\"\n",
        "    except Exception:\n",
        "        return \"\"\n",
        "\n",
        "def extract_potential_reasoning(response: str) -> str:\n",
        "    \"\"\"\n",
        "    태그가 없는 경우에도 풀이 과정으로 볼 수 있는 텍스트를 추출합니다.\n",
        "    \"\"\"\n",
        "    # 답변 부분 추출\n",
        "    answer_part = extract_xml_answer(response)\n",
        "    \n",
        "    # 전체 응답에서 답변 부분이나 <answer> 태그 관련 텍스트 제거\n",
        "    full_text = response\n",
        "    if answer_part:\n",
        "        full_text = full_text.replace(f\"<answer>{answer_part}</answer>\", \"\")\n",
        "    full_text = full_text.replace(\"<answer>\", \"\").replace(\"</answer>\", \"\")\n",
        "    \n",
        "    # 남은 텍스트에서 <reasoning> 태그 관련 텍스트 제거\n",
        "    reasoning = full_text.replace(\"<reasoning>\", \"\").replace(\"</reasoning>\", \"\").strip()\n",
        "    \n",
        "    # 내용이 너무 짧으면 유효한 풀이 과정으로 간주하지 않음\n",
        "    if len(reasoning.split()) < 10:  # 10단어 미만이면 너무 짧다고 판단\n",
        "        return \"\"\n",
        "    \n",
        "    return reasoning\n",
        "\n",
        "def generate_reasoning_score(question: str, response: str, expected_answer: str, strict_mode=False) -> tuple[float, str, dict]:\n",
        "    \"\"\"\n",
        "    Gemini 모델을 사용하여 풀이 과정(reasoning)에 대한 점수를 생성합니다.\n",
        "    \n",
        "    반환값:\n",
        "    - 풀이 과정 점수 (0-5)\n",
        "    - 간략한 피드백\n",
        "    - 상세 평가 정보 (디버깅용)\n",
        "    \"\"\"\n",
        "    # 캐시 키 생성 (질문과 응답의 일부를 사용)\n",
        "    cache_key = f\"{question[:50]}_{response[:100]}_{strict_mode}\"\n",
        "    \n",
        "    # 캐시에서 결과 확인\n",
        "    if cache_key in reasoning_score_cache:\n",
        "        result = reasoning_score_cache[cache_key]\n",
        "        logger.debug(f\"캐시에서 결과 로드: {result}\")\n",
        "        # 캐시에서는 점수와 피드백만 반환하므로 빈 평가 정보 추가\n",
        "        return result[0], result[1], {\"cached\": True}\n",
        "    \n",
        "    # 풀이 과정 추출\n",
        "    reasoning = extract_reasoning(response)\n",
        "    \n",
        "    # 엄격하지 않은 모드에서 태그가 없으면 다른 방법으로 풀이 과정 추출 시도\n",
        "    if not reasoning and not strict_mode:\n",
        "        reasoning = extract_potential_reasoning(response)\n",
        "        if reasoning:\n",
        "            logger.info(f\"태그 없이 추출된 풀이 과정: {reasoning[:100]}...\")\n",
        "    \n",
        "    # 풀이 과정이 없으면 0점 반환\n",
        "    if not reasoning:\n",
        "        logger.warning(\"풀이 과정이 없거나 너무 짧습니다.\")\n",
        "        return 0.0, \"풀이 과정이 없거나 너무 짧습니다.\", {\"error\": \"풀이 과정 없음\"}\n",
        "    \n",
        "    # Gemini 모델 초기화\n",
        "    try:\n",
        "        gemini_model = setup_gemini()\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Gemini API 설정 오류: {e}\")\n",
        "        return 0.0, f\"API 오류: {str(e)}\", {\"error\": str(e)}\n",
        "    \n",
        "    scoring_prompt = f\"\"\"\n",
        "    당신은 수학 문제 풀이 과정을 평가하는 전문가입니다. \n",
        "    학생의 풀이 과정을 분석하고 0-5 점수로 평가해주세요.\n",
        "    \n",
        "    문제:\n",
        "    {question}\n",
        "    \n",
        "    정답:\n",
        "    {expected_answer}\n",
        "    \n",
        "    학생의 풀이 과정:\n",
        "    {reasoning}\n",
        "    \n",
        "    다음 기준으로 풀이 과정을 평가하세요:\n",
        "    - 5점: 탁월한 풀이 과정. 논리적이고 명확하며, 가장 효율적인 방법 사용\n",
        "    - 4점: 매우 좋은 풀이 과정. 논리적이고 단계별로 잘 설명됨\n",
        "    - 3점: 좋은 풀이 과정. 올바른 접근법이지만 설명이 다소 부족함\n",
        "    - 2점: 기본적인 풀이 과정. 정답에 도달할 수 있지만 논리적 비약이 있음\n",
        "    - 1점: 부족한 풀이 과정. 오류가 있거나 불완전함\n",
        "    - 0점: 풀이 과정이 없거나 완전히 잘못됨\n",
        "    \n",
        "    JSON 형식으로 다음과 같이 응답해주세요:\n",
        "    {{\n",
        "        \"reasoning_score\": 점수(0-5),\n",
        "        \"brief_feedback\": \"한 문장으로 된 간략한 피드백\",\n",
        "        \"detailed_evaluation\": \"그 문제에 핵심적으로 필요한 풀이 과정과 비교해 학생의 풀이 과정에서 핵심을 평가. (2-3문장)\"\n",
        "    }}\n",
        "    \n",
        "    다른 설명 없이 JSON만 반환해주세요. 백틱(```)이나 다른 마크다운 형식을 사용하지 마세요.\n",
        "    \"\"\"\n",
        "    \n",
        "    logger.info(f\"Gemini API에 평가 요청 전송 중...\")\n",
        "    \n",
        "    try:\n",
        "        # API 호출 전 짧은 대기 (API 제한 방지)\n",
        "        time.sleep(0.5)\n",
        "        \n",
        "        # Gemini 모델에 평가 요청\n",
        "        start_time = datetime.now()\n",
        "        result = gemini_model.generate_content(scoring_prompt)\n",
        "        end_time = datetime.now()\n",
        "        api_response_time = (end_time - start_time).total_seconds()\n",
        "        \n",
        "        result_text = result.text\n",
        "        logger.info(f\"Gemini API 응답 수신 (응답 시간: {api_response_time:.2f}초)\")\n",
        "        \n",
        "        # 백틱(```) 제거 - JSON 파싱 오류 해결\n",
        "        result_text = result_text.replace('```json', '').replace('```', '').strip()\n",
        "        \n",
        "        # JSON 파싱\n",
        "        try:\n",
        "            result_json = json.loads(result_text)\n",
        "            reasoning_score = result_json.get(\"reasoning_score\", 0)\n",
        "            brief_feedback = result_json.get(\"brief_feedback\", \"\")\n",
        "            detailed_evaluation = result_json.get(\"detailed_evaluation\", \"\")\n",
        "            \n",
        "            # 평가 결과 로깅\n",
        "            logger.info(f\"풀이 과정 평가 결과: {reasoning_score}/5\")\n",
        "            logger.info(f\"간략 피드백: {brief_feedback}\")\n",
        "            logger.info(f\"상세 평가: {detailed_evaluation}\")\n",
        "            \n",
        "            # 평가 기록 저장\n",
        "            evaluation_record = {\n",
        "                \"timestamp\": datetime.now().isoformat(),\n",
        "                \"question\": question[:100] + \"...\" if len(question) > 100 else question,\n",
        "                \"reasoning\": reasoning[:100] + \"...\" if len(reasoning) > 100 else reasoning,\n",
        "                \"expected_answer\": expected_answer,\n",
        "                \"score\": reasoning_score,\n",
        "                \"brief_feedback\": brief_feedback,\n",
        "                \"detailed_evaluation\": detailed_evaluation,\n",
        "                \"response_time\": api_response_time\n",
        "            }\n",
        "            evaluation_history.append(evaluation_record)\n",
        "            \n",
        "            # 결과를 캐시에 저장 (점수와 피드백만)\n",
        "            result_tuple = (float(reasoning_score), brief_feedback)\n",
        "            reasoning_score_cache[cache_key] = result_tuple\n",
        "            \n",
        "            # 평가 정보 반환 (디버깅용)\n",
        "            evaluation_info = {\n",
        "                \"score\": reasoning_score,\n",
        "                \"brief_feedback\": brief_feedback,\n",
        "                \"detailed_evaluation\": detailed_evaluation,\n",
        "                \"response_time\": api_response_time\n",
        "            }\n",
        "            \n",
        "            return float(reasoning_score), brief_feedback, evaluation_info\n",
        "            \n",
        "        except json.JSONDecodeError as e:\n",
        "            error_msg = f\"JSON 파싱 오류: {result_text} - 오류: {str(e)}\"\n",
        "            logger.error(error_msg)\n",
        "            \n",
        "            # 응급 처치: 숫자만 추출해서 점수로 사용\n",
        "            import re\n",
        "            score_match = re.search(r'\"reasoning_score\":\\s*(\\d+)', result_text)\n",
        "            if score_match:\n",
        "                try:\n",
        "                    extracted_score = float(score_match.group(1))\n",
        "                    logger.info(f\"응급 처치: JSON 파싱 실패했지만 점수 추출 성공: {extracted_score}\")\n",
        "                    \n",
        "                    # 피드백 추출 시도\n",
        "                    feedback_match = re.search(r'\"brief_feedback\":\\s*\"([^\"]+)\"', result_text)\n",
        "                    extracted_feedback = feedback_match.group(1) if feedback_match else \"파싱 오류, 점수만 추출됨\"\n",
        "                    \n",
        "                    # 평가 기록 저장 (부분 정보)\n",
        "                    evaluation_record = {\n",
        "                        \"timestamp\": datetime.now().isoformat(),\n",
        "                        \"question\": question[:100] + \"...\" if len(question) > 100 else question,\n",
        "                        \"reasoning\": reasoning[:100] + \"...\" if len(reasoning) > 100 else reasoning,\n",
        "                        \"expected_answer\": expected_answer,\n",
        "                        \"score\": extracted_score,\n",
        "                        \"brief_feedback\": extracted_feedback,\n",
        "                        \"detailed_evaluation\": \"파싱 오류로 인해 추출 실패\",\n",
        "                        \"response_time\": api_response_time,\n",
        "                        \"parsing_error\": True\n",
        "                    }\n",
        "                    evaluation_history.append(evaluation_record)\n",
        "                    \n",
        "                    # 결과를 캐시에 저장\n",
        "                    result_tuple = (extracted_score, extracted_feedback)\n",
        "                    reasoning_score_cache[cache_key] = result_tuple\n",
        "                    \n",
        "                    return extracted_score, extracted_feedback, {\"error\": error_msg, \"partial_parse\": True}\n",
        "                except Exception as inner_e:\n",
        "                    logger.error(f\"응급 처치 실패: {inner_e}\")\n",
        "            \n",
        "            return 0.0, \"JSON 파싱 오류\", {\"error\": error_msg, \"raw_response\": result_text}\n",
        "            \n",
        "    except Exception as e:\n",
        "        error_msg = f\"Gemini API 오류: {e}\"\n",
        "        logger.error(error_msg)\n",
        "        return 0.0, f\"API 오류: {str(e)}\", {\"error\": error_msg}\n",
        "\n",
        "def reasoning_quality_reward_func(prompts, completions, answer, **kwargs) -> list[float]:\n",
        "    \"\"\"\n",
        "    풀이 과정(reasoning)의 품질을 평가하고 보상을 계산합니다.\n",
        "    \"\"\"\n",
        "    responses = [completion[0]['content'] for completion in completions]\n",
        "    questions = [prompt[-1]['content'] for prompt in prompts]\n",
        "    \n",
        "    # 현재 학습 단계 정보 (있는 경우)\n",
        "    current_step = kwargs.get('current_step', 0)\n",
        "    total_steps = kwargs.get('total_steps', 1000)\n",
        "    strict_mode = current_step > total_steps / 2  # 학습 후반부에는 엄격한 모드 적용\n",
        "    \n",
        "    logger.info(f\"풀이 과정 평가 시작 (현재 단계: {current_step}/{total_steps}, 엄격 모드: {strict_mode})\")\n",
        "    \n",
        "    rewards = []\n",
        "    feedbacks = []  # 디버깅 및 로깅용\n",
        "    \n",
        "    for idx, (question, response, expected_answer) in enumerate(zip(questions, responses, answer)):\n",
        "        # 풀이 과정 점수 생성 (0-5)\n",
        "        reasoning_score, brief_feedback, evaluation_info = generate_reasoning_score(\n",
        "            question, response, expected_answer, strict_mode=strict_mode\n",
        "        )\n",
        "        \n",
        "        # 점수를 0-1 범위로 정규화\n",
        "        normalized_score = reasoning_score / 5.0\n",
        "        \n",
        "        # 디버깅 정보 (첫 번째 샘플만)\n",
        "        if idx == 0:\n",
        "            print('-'*20)\n",
        "            print(f\"풀이 과정 평가:\")\n",
        "            print(f\"질문: {question[:100]}...\")\n",
        "            \n",
        "            # 풀이 과정 출력\n",
        "            reasoning = extract_reasoning(response)\n",
        "            if not reasoning and not strict_mode:\n",
        "                reasoning = extract_potential_reasoning(response)\n",
        "                print(f\"태그 없이 추출된 풀이 과정: {reasoning[:100]}...\")\n",
        "            else:\n",
        "                print(f\"풀이 과정: {reasoning[:100]}...\")\n",
        "            \n",
        "            print(f\"풀이 과정 점수: {reasoning_score}/5 ({normalized_score:.2f})\")\n",
        "            print(f\"피드백: {brief_feedback}\")\n",
        "            \n",
        "            # 캐시에서 가져온 결과가 아닌 경우 상세 평가 정보 출력\n",
        "            if not evaluation_info.get(\"cached\", False):\n",
        "                print(f\"상세 평가: {evaluation_info.get('detailed_evaluation', '정보 없음')}\")\n",
        "                print(f\"API 응답 시간: {evaluation_info.get('response_time', 0):.2f}초\")\n",
        "        \n",
        "        rewards.append(normalized_score)\n",
        "        feedbacks.append(brief_feedback)\n",
        "    \n",
        "    return rewards\n",
        "\n",
        "# 보상 함수 조합 예시\n",
        "def combined_reward_func(prompts, completions, answer, **kwargs) -> list[float]:\n",
        "    \"\"\"\n",
        "    여러 보상 함수의 결과를 조합하여 최종 보상을 계산합니다.\n",
        "    \"\"\"\n",
        "    # 기존 보상 함수들\n",
        "    correctness_rewards = correctness_reward_func(prompts, completions, answer, **kwargs)\n",
        "    format_rewards = xmlcount_reward_func(completions, **kwargs)\n",
        "    \n",
        "    # 새로운 풀이 과정 평가 보상\n",
        "    reasoning_rewards = reasoning_quality_reward_func(prompts, completions, answer, **kwargs)\n",
        "    \n",
        "    # 보상 조합 (가중치 조정 가능)\n",
        "    combined_rewards = []\n",
        "    for idx, (c_reward, f_reward, r_reward) in enumerate(zip(correctness_rewards, format_rewards, reasoning_rewards)):\n",
        "        # 정확성에 0.6, 형식에 0.1, 풀이 과정에 0.3의 가중치 부여\n",
        "        combined_reward = 0.6 * c_reward + 0.1 * f_reward + 0.3 * r_reward\n",
        "        combined_rewards.append(combined_reward)\n",
        "        \n",
        "        # 첫 번째 샘플의 보상 내역 출력\n",
        "        if idx == 0:\n",
        "            print(f\"보상 내역 - 정확성: {c_reward:.2f}, 형식: {f_reward:.2f}, 풀이 과정: {r_reward:.2f}\")\n",
        "            print(f\"최종 보상: {combined_reward:.2f}\")\n",
        "    \n",
        "    return combined_rewards\n",
        "\n",
        "\n",
        "# 평가 결과 요약 및 분석 함수\n",
        "def summarize_evaluations(n_recent=10):\n",
        "    \"\"\"최근 n개의 평가 결과를 요약하고 분석합니다.\"\"\"\n",
        "    if not evaluation_history:\n",
        "        print(\"평가 기록이 없습니다.\")\n",
        "        return\n",
        "    \n",
        "    recent_evals = evaluation_history[-n_recent:] if len(evaluation_history) >= n_recent else evaluation_history\n",
        "    \n",
        "    print(f\"\\n=== 최근 {len(recent_evals)}개 평가 결과 요약 ===\")\n",
        "    \n",
        "    # 평균 점수 계산\n",
        "    avg_score = sum(float(eval_record[\"score\"]) for eval_record in recent_evals) / len(recent_evals)\n",
        "    print(f\"평균 점수: {avg_score:.2f}/5\")\n",
        "    \n",
        "    # 점수 분포\n",
        "    score_distribution = {}\n",
        "    for i in range(6):  # 0-5점\n",
        "        score_distribution[i] = sum(1 for eval_record in recent_evals if float(eval_record[\"score\"]) == i)\n",
        "    \n",
        "    print(\"점수 분포:\")\n",
        "    for score, count in score_distribution.items():\n",
        "        percentage = (count / len(recent_evals)) * 100\n",
        "        print(f\"  {score}점: {count}개 ({percentage:.1f}%)\")\n",
        "    \n",
        "    # 평균 응답 시간\n",
        "    avg_response_time = sum(eval_record.get(\"response_time\", 0) for eval_record in recent_evals) / len(recent_evals)\n",
        "    print(f\"평균 API 응답 시간: {avg_response_time:.2f}초\")\n",
        "    \n",
        "    # 자주 언급되는 피드백 키워드 분석\n",
        "    all_feedback = \" \".join([eval_record[\"brief_feedback\"] + \" \" + eval_record.get(\"detailed_evaluation\", \"\") \n",
        "                           for eval_record in recent_evals])\n",
        "    \n",
        "    # 간단한 키워드 빈도 분석\n",
        "    keywords = [\"논리적\", \"명확\", \"효율적\", \"오류\", \"불완전\", \"단계별\", \"설명\", \"접근법\"]\n",
        "    keyword_counts = {keyword: all_feedback.lower().count(keyword) for keyword in keywords}\n",
        "    \n",
        "    print(\"\\n자주 언급되는 피드백 키워드:\")\n",
        "    for keyword, count in sorted(keyword_counts.items(), key=lambda x: x[1], reverse=True):\n",
        "        if count > 0:\n",
        "            print(f\"  '{keyword}': {count}회 언급\")\n",
        "    \n",
        "    # 최근 몇 개의 상세 평가 출력\n",
        "    print(\"\\n최근 평가 상세 내용:\")\n",
        "    for i, eval_record in enumerate(recent_evals[-3:]):  # 최근 3개만\n",
        "        print(f\"\\n[{i+1}] 점수: {eval_record['score']}/5\")\n",
        "        print(f\"간략 피드백: {eval_record['brief_feedback']}\")\n",
        "        print(f\"상세 평가: {eval_record.get('detailed_evaluation', '정보 없음')}\")\n",
        "\n",
        "def save_evaluation_results():\n",
        "    \"\"\"현재까지의 평가 결과를 JSON 파일로 저장합니다.\"\"\"\n",
        "    if not evaluation_history:\n",
        "        print(\"저장할 평가 기록이 없습니다.\")\n",
        "        return None\n",
        "    \n",
        "    # 디렉토리 생성 (없는 경우)\n",
        "    os.makedirs(\"evaluation_results\", exist_ok=True)\n",
        "    \n",
        "    save_path = f\"evaluation_results/eval_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
        "    \n",
        "    try:\n",
        "        with open(save_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(evaluation_history, f, ensure_ascii=False, indent=2)\n",
        "        \n",
        "        print(f\"\\n평가 결과가 '{save_path}'에 저장되었습니다.\")\n",
        "        return save_path\n",
        "    except Exception as e:\n",
        "        print(f\"평가 결과 저장 중 오류 발생: {e}\")\n",
        "        return None\n",
        "\n",
        "# GRPO 훈련 중 주기적으로 평가 결과를 확인하는 함수\n",
        "def check_evaluation_progress(current_step, total_steps):\n",
        "    \"\"\"훈련 중 주기적으로 평가 결과를 확인합니다.\"\"\"\n",
        "    # 일정 간격으로만 실행 (예: 10% 진행될 때마다)\n",
        "    if total_steps == 0:  # 0으로 나누기 방지\n",
        "        progress_percentage = 0\n",
        "    else:\n",
        "        progress_percentage = (current_step / total_steps) * 100\n",
        "    \n",
        "    print(f\"\\n=== 훈련 진행 상황: {progress_percentage:.1f}% ({current_step}/{total_steps}) ===\")\n",
        "    \n",
        "    # 평가 결과 확인\n",
        "    if evaluation_history:\n",
        "        # 최근 평가 결과 요약\n",
        "        recent_count = min(5, len(evaluation_history))\n",
        "        print(f\"최근 {recent_count}개 평가 결과:\")\n",
        "        \n",
        "        for i, eval_record in enumerate(evaluation_history[-recent_count:]):\n",
        "            print(f\"[{i+1}] 점수: {eval_record.get('score', 'N/A')}/5\")\n",
        "            print(f\"    피드백: {eval_record.get('brief_feedback', 'N/A')}\")\n",
        "    else:\n",
        "        print(\"아직 평가 기록이 없습니다.\")\n",
        "\n",
        "# 테스트 함수 - 실제 평가 과정을 테스트하기 위한 함수\n",
        "def test_reasoning_evaluation(question, response, expected_answer, strict_mode=False):\n",
        "    \"\"\"풀이 과정 평가 기능을 테스트합니다.\"\"\"\n",
        "    print(f\"\\n=== 풀이 과정 평가 테스트 ===\")\n",
        "    print(f\"질문: {question}\")\n",
        "    print(f\"응답: {response}\")\n",
        "    print(f\"정답: {expected_answer}\")\n",
        "    print(f\"엄격 모드: {strict_mode}\")\n",
        "    \n",
        "    # 풀이 과정 추출\n",
        "    reasoning = extract_reasoning(response)\n",
        "    if not reasoning and not strict_mode:\n",
        "        reasoning = extract_potential_reasoning(response)\n",
        "    \n",
        "    print(f\"\\n추출된 풀이 과정: {reasoning}\")\n",
        "    \n",
        "    # 평가 실행\n",
        "    score, feedback, evaluation_info = generate_reasoning_score(\n",
        "        question, response, expected_answer, strict_mode=strict_mode\n",
        "    )\n",
        "    \n",
        "    print(f\"\\n평가 결과:\")\n",
        "    print(f\"점수: {score}/5\")\n",
        "    print(f\"피드백: {feedback}\")\n",
        "    \n",
        "    if \"detailed_evaluation\" in evaluation_info:\n",
        "        print(f\"상세 평가: {evaluation_info['detailed_evaluation']}\")\n",
        "    \n",
        "    if \"response_time\" in evaluation_info:\n",
        "        print(f\"API 응답 시간: {evaluation_info['response_time']:.2f}초\")\n",
        "    \n",
        "    # 캐시 테스트\n",
        "    print(\"\\n캐시 테스트 (동일한 입력으로 다시 호출)...\")\n",
        "    start_time = time.time()\n",
        "    cached_score, cached_feedback, cached_info = generate_reasoning_score(\n",
        "        question, response, expected_answer, strict_mode=strict_mode\n",
        "    )\n",
        "    cache_time = time.time() - start_time\n",
        "    \n",
        "    print(f\"캐시된 점수: {cached_score}/5 (응답 시간: {cache_time:.4f}초)\")\n",
        "    print(f\"캐시된 피드백: {cached_feedback}\")\n",
        "    \n",
        "    return score, feedback, evaluation_info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 모델을 bfloat16으로 변환\n",
        "model = model.to(torch.bfloat16)\n",
        "print(f\"모델 데이터 타입: {next(model.parameters()).dtype}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import TrainerCallback\n",
        "from typing import Dict, Any\n",
        "import os\n",
        "import torch\n",
        "from trl import GRPOConfig, GRPOTrainer\n",
        "\n",
        "# bfloat16 지원 여부 확인\n",
        "bf16_supported = torch.cuda.is_bf16_supported()\n",
        "\n",
        "# 훈련 인자 설정\n",
        "training_args = GRPOConfig(\n",
        "    use_vllm=False, # ✅ vLLM 지원 여부 불확실 → False로 변경\n",
        "    learning_rate=5e-6,\n",
        "    adam_beta1=0.9,\n",
        "    adam_beta2=0.99,\n",
        "    weight_decay=0.1,\n",
        "    warmup_ratio=0.1,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    optim=\"adamw_bnb_8bit\",\n",
        "    logging_steps=1,\n",
        "    bf16=True, # ✅ bfloat16이 가능하면 사용\n",
        "    fp16=False, # ✅ fp16 사용 안 함 (오버플로우 방지)\n",
        "    per_device_train_batch_size=4, # ✅ batch size 감소 (OOM 방지)\n",
        "    gradient_accumulation_steps=1, # ✅ grad accumulation 추가\n",
        "    num_generations=4,\n",
        "    max_prompt_length=256,\n",
        "    max_completion_length=200,\n",
        "    max_steps=2000,\n",
        "    save_steps=500,\n",
        "    max_grad_norm=0.1,\n",
        "    report_to=\"none\",\n",
        "    output_dir=\"outputs\",\n",
        "    do_train=True,\n",
        "    # 멀티 GPU 관련 설정 추가\n",
        "    ddp_find_unused_parameters=False,\n",
        "    dataloader_num_workers=2,\n",
        ")\n",
        "\n",
        "# 평가 결과를 트레이너 메트릭에 통합하는 콜백\n",
        "class ReasoningEvaluationCallback(TrainerCallback):\n",
        "    def __init__(self):\n",
        "        self.step = 0\n",
        "        self.reasoning_scores = []  # 풀이 과정 점수 기록\n",
        "        self.total_scores = []      # 총점 기록\n",
        "    \n",
        "    def on_init_end(self, args, state, control, **kwargs):\n",
        "        \"\"\"초기화 완료 시 호출\"\"\"\n",
        "        print(\"훈련 초기화 완료. 풀이 과정 평가 모니터링 시작...\")\n",
        "        return control\n",
        "    \n",
        "    # 메서드 시그니처 수정 - **kwargs만 사용\n",
        "    def on_step_end(self, args, state, control, **kwargs):\n",
        "        \"\"\"각 스텝 완료 시 호출\"\"\"\n",
        "        self.step += 1\n",
        "        \n",
        "        # 10 스텝마다 평가 결과 확인 및 로깅\n",
        "        if self.step % 10 == 0:\n",
        "            print(f\"스텝 {self.step}/{args.max_steps} 완료\")\n",
        "            \n",
        "            # 최근 평가 결과 수집\n",
        "            if evaluation_history:\n",
        "                recent_evals = evaluation_history[-10:]  # 최근 10개\n",
        "                \n",
        "                # 평균 점수 계산\n",
        "                avg_score = sum(float(eval_record.get(\"score\", 0)) for eval_record in recent_evals) / len(recent_evals)\n",
        "                \n",
        "                # 트레이너에 메트릭 로깅\n",
        "                metrics = {\n",
        "                    \"reasoning_score\": avg_score,\n",
        "                    \"reasoning_score_normalized\": avg_score / 5.0,  # 0-1 범위로 정규화\n",
        "                }\n",
        "                \n",
        "                # 트레이너의 log_metrics 메서드 호출\n",
        "                if hasattr(kwargs.get('model', None), 'log_metrics'):\n",
        "                    kwargs['model'].log_metrics(\"train\", metrics)\n",
        "                    kwargs['model'].save_metrics(\"train\", metrics, combined=True)\n",
        "                    print(f\"메트릭 로깅 완료: {metrics}\")\n",
        "                \n",
        "                # 점수 기록\n",
        "                self.reasoning_scores.append(avg_score)\n",
        "                \n",
        "                # 간단한 요약 출력\n",
        "                print(f\"최근 평균 풀이 과정 점수: {avg_score:.2f}/5\")\n",
        "        \n",
        "        return control\n",
        "    \n",
        "    def on_train_end(self, args, state, control, **kwargs):\n",
        "        \"\"\"훈련 완료 시 호출\"\"\"\n",
        "        print(\"훈련 완료. 최종 평가 결과 기록 중...\")\n",
        "        \n",
        "        # 전체 평가 결과 요약\n",
        "        if evaluation_history:\n",
        "            # 평균 점수 계산\n",
        "            avg_score = sum(float(eval_record.get(\"score\", 0)) for eval_record in evaluation_history) / len(evaluation_history)\n",
        "            \n",
        "            # 최종 메트릭 기록\n",
        "            final_metrics = {\n",
        "                \"final_reasoning_score\": avg_score,\n",
        "                \"final_reasoning_score_normalized\": avg_score / 5.0,\n",
        "                \"num_evaluations\": len(evaluation_history)\n",
        "            }\n",
        "            \n",
        "            # 평가 결과 파일로 저장\n",
        "            save_path = save_evaluation_results()\n",
        "            \n",
        "            # 트레이너 상태에 평가 결과 파일 경로 추가\n",
        "            if save_path and hasattr(state, 'log_history'):\n",
        "                state.log_history.append({\n",
        "                    \"reasoning_evaluation_file\": save_path,\n",
        "                    \"step\": self.step\n",
        "                })\n",
        "        \n",
        "        return control\n",
        "\n",
        "# 평가 결과를 직접 GRPO 트레이너에 통합하는 함수\n",
        "def integrate_reasoning_evaluation(prompts, completions, answer, **kwargs) -> list[float]:\n",
        "    \"\"\"\n",
        "    풀이 과정 평가 결과를 계산하고, 결과를 트레이너에 직접 통합합니다.\n",
        "    \"\"\"\n",
        "    # 기존 함수와 동일하게 보상 계산\n",
        "    rewards = reasoning_quality_reward_func(prompts, completions, answer, **kwargs)\n",
        "    \n",
        "    # 최근 평가 결과가 있으면 기록\n",
        "    if evaluation_history:\n",
        "        # 현재 스텝 정보 (있는 경우)\n",
        "        current_step = kwargs.get('current_step', 0)\n",
        "        \n",
        "        # 평균 점수 계산\n",
        "        recent_evals = evaluation_history[-len(rewards):]  # 현재 배치와 동일한 수의 최근 평가\n",
        "        if recent_evals:\n",
        "            avg_score = sum(float(eval_record.get(\"score\", 0)) for eval_record in recent_evals) / len(recent_evals)\n",
        "            \n",
        "            # 로그에 기록\n",
        "            print(f\"현재 배치 평균 풀이 과정 점수: {avg_score:.2f}/5\")\n",
        "    \n",
        "    return rewards\n",
        "\n",
        "# 콜백 인스턴스 생성\n",
        "evaluation_callback = EvaluationMonitorCallback()\n",
        "\n",
        "# GRPO 트레이너 설정 - 풀이 과정 평가 보상 함수 추가\n",
        "# GRPO 트레이너 설정\n",
        "trainer = GRPOTrainer(\n",
        "    model = model,\n",
        "    processing_class = tokenizer,\n",
        "    reward_funcs = [\n",
        "        xmlcount_reward_func,\n",
        "        soft_format_reward_func,\n",
        "        strict_format_reward_func,\n",
        "        int_reward_func,\n",
        "        correctness_reward_func,\n",
        "        # 수정된 함수 사용\n",
        "        integrate_reasoning_evaluation,\n",
        "    ],\n",
        "    args = training_args,\n",
        "    train_dataset = dataset,\n",
        "    callbacks = [ReasoningEvaluationCallback()],  # 수정된 콜백 사용\n",
        ")\n",
        "# 학습 시작 전 테스트 (선택 사항)\n",
        "if False:  # 테스트하려면 True로 변경\n",
        "    # 샘플 데이터로 풀이 과정 평가 테스트\n",
        "    sample_idx = 0\n",
        "    sample = dataset[sample_idx]\n",
        "    question = sample['prompt'][-1]['content']\n",
        "    expected_answer = sample['answer']\n",
        "    \n",
        "    # 모델의 현재 응답 생성\n",
        "    inputs = tokenizer(question, return_tensors=\"pt\").to(model.device)\n",
        "    outputs = model.generate(**inputs, max_length=512)\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    \n",
        "    # 평가 테스트\n",
        "    test_reasoning_evaluation(question, response, expected_answer)\n",
        "    \n",
        "    print(\"\\n테스트 완료. 계속하려면 Enter를 누르세요...\")\n",
        "    input()\n",
        "\n",
        "# 학습 시작\n",
        "print(\"학습 시작...\")\n",
        "trainer.train()\n",
        "\n",
        "# 학습 완료 후 평가 결과 저장\n",
        "print(\"학습 완료. 평가 결과 저장 중...\")\n",
        "save_path = save_evaluation_results()\n",
        "print(f\"평가 결과가 '{save_path}'에 저장되었습니다.\")\n",
        "\n",
        "# 평가 결과 요약\n",
        "summarize_evaluations()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "GRPO",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0ca67b0c4ca64eb788358a51308f6b97": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ac03aff5c314b00ac938c80eb7b2f8a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c522d78b1834068bd4b155d0f87a4d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ca67b0c4ca64eb788358a51308f6b97",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_83c3c811923a4642aba156d1215b39d2",
            "value": 1
          }
        },
        "3febcf8a8eca40c28aafc697f3ec8776": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5f3d96b613e94e9984d4599ca9ca7b17": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea549fffa8c2469888d1668158bc105c",
            "placeholder": "​",
            "style": "IPY_MODEL_98b432b98839428f85d91580c21e80e2",
            "value": ""
          }
        },
        "6221f0be3b8d48e797c873565a216680": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66c3271554b1455eb56be55c9241e45e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fee4f852c9744a07b909e586e3615604",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3febcf8a8eca40c28aafc697f3ec8776",
            "value": 1
          }
        },
        "697faad6643a43aca98015da4faef186": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "769bde36e2ba4434bddd78e7d5911be4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ac03aff5c314b00ac938c80eb7b2f8a",
            "placeholder": "​",
            "style": "IPY_MODEL_88c63d94a05a42c49d5f8958a27987a6",
            "value": ""
          }
        },
        "83c3c811923a4642aba156d1215b39d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "88c63d94a05a42c49d5f8958a27987a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "94873c3c077e483790b34f95c421f484": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98b432b98839428f85d91580c21e80e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a23afba19c2a4d3a90d771fc55f8d490": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e863bf099e064da7b482c21fe7b77de7",
            "placeholder": "​",
            "style": "IPY_MODEL_697faad6643a43aca98015da4faef186",
            "value": "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:16&lt;00:00, 16.13s/it]\n"
          }
        },
        "b4e1eb8eeb064c88a2142e474fb8327f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d36b61cf796c429080e93ea838a3759e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4e1eb8eeb064c88a2142e474fb8327f",
            "placeholder": "​",
            "style": "IPY_MODEL_da10502506f9448c9de94f1ddd84d3b1",
            "value": "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:27&lt;00:00, 27.50s/it]\n"
          }
        },
        "d8d0dca36cfc47f0919924da07c231e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5f3d96b613e94e9984d4599ca9ca7b17",
              "IPY_MODEL_66c3271554b1455eb56be55c9241e45e",
              "IPY_MODEL_d36b61cf796c429080e93ea838a3759e"
            ],
            "layout": "IPY_MODEL_94873c3c077e483790b34f95c421f484"
          }
        },
        "da10502506f9448c9de94f1ddd84d3b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e6cc388e78c14abfaa49d2be6fa1b5d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_769bde36e2ba4434bddd78e7d5911be4",
              "IPY_MODEL_3c522d78b1834068bd4b155d0f87a4d7",
              "IPY_MODEL_a23afba19c2a4d3a90d771fc55f8d490"
            ],
            "layout": "IPY_MODEL_6221f0be3b8d48e797c873565a216680"
          }
        },
        "e863bf099e064da7b482c21fe7b77de7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea549fffa8c2469888d1668158bc105c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fee4f852c9744a07b909e586e3615604": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
